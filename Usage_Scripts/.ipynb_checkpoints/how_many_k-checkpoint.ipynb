{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23659b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5226ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\subFinder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7aa97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this script we will train supervised models\n",
    "# library imports\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from Codes.Supervised_Trainer import run_end_to_end\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e84f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## read the data\n",
    "# sup_data_path = r\"Data/Supervised_Sequences/dbCAN-PUL_07-01-2022.xlsx\"\n",
    "new_path = r\"D:\\subFinder\\Data\\Supervised_Sequences\\Table S1.xls\"\n",
    "data = pd.read_excel(new_path)\n",
    "data[\"updated_substrate (09/01/2022)\"] = data[\"updated_substrate (09/01/2022)\"].str.strip()\n",
    "data[\"updated_substrate (09/01/2022)\"] = data[\"updated_substrate (09/01/2022)\"].str.strip()\n",
    "\n",
    "\n",
    "## removing the catch all classes\n",
    "## for example multiple substrates and others \n",
    "old_data = pd.read_csv('Data/Supervised_Sequences/pul_seq_low_high_substr_year_corrected.tsv', sep = \"\\t\")\n",
    "\n",
    "old_data[\"high_level_substr\"] = old_data[\"high_level_substr\"].str.strip()\n",
    "\n",
    "bad_puls = old_data[old_data[\"high_level_substr\"].isin([\"multiple_substrates\", \"mono/di/trisaccharide\", \"-\", \"human milk oligosaccharide\", \n",
    "                                            \"glycoprotein\", \"plant polysaccharide\", \"cellobiose\"])][\"PULid\"].values\n",
    "\n",
    "\n",
    "data = data[~data[\"PUL ID\"].isin(bad_puls)]\n",
    "\n",
    "data = data[[\"PUL ID\", \"updated_substrate (09/01/2022)\"]]\n",
    "data = pd.merge(data, old_data[[\"PULid\",\"sig_gene_seq\"]], left_on = [\"PUL ID\"], right_on = [\"PULid\"], how = \"left\")\n",
    "data.columns = [\"PUL ID\", \"high_level_substr\", \"PULid\", \"sig_gene_seq\"]\n",
    "\n",
    "data = data[~data[\"PUL ID\"].isin(bad_puls)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8133952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the data\n",
    "# sup_data_path = r\"Data/Supervised_Sequences/dbCAN-PUL_07-01-2022.xlsx\"\n",
    "new_sup_data_with_nulls = pd.read_csv(r\"D:\\subFinder\\Data\\Supervised_Sequences\\supervised_seq_with_null.tsv\", sep = \"\\t\", \n",
    "                                      header = None)\n",
    "new_sup_data_with_nulls.columns = [\"PUL ID\", \"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa89063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\AppData\\Local\\Temp\\ipykernel_13448\\282975859.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data = data.drop([\"sig_gene_seq\"],1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(data, new_sup_data_with_nulls, on = [\"PUL ID\"], how = \"left\")\n",
    "data = data.drop([\"sig_gene_seq\"],1)\n",
    "data.columns = ['PUL ID', 'high_level_substr', 'PULid', 'sig_gene_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c3135ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "capsule polysaccharide synthesis      106\n",
       "pectin                                 39\n",
       "xylan                                  35\n",
       "beta-glucan                            21\n",
       "alginate                               21\n",
       "host glycan                            19\n",
       "cellulose                              16\n",
       "starch                                 16\n",
       "chitin                                 15\n",
       "galactomannan                          15\n",
       "glycosaminoglycan                      14\n",
       "arabinan                               12\n",
       "galactan                               10\n",
       "alpha-mannan                            8\n",
       "beta-mannan                             8\n",
       "carrageenan                             8\n",
       "xyloglucan                              7\n",
       "fructan                                 7\n",
       "arabinoxylan                            6\n",
       "agarose                                 6\n",
       "arabinogalactan                         5\n",
       "capsule polysaccharide degradation      4\n",
       "beta-galactooligosaccharide             4\n",
       "glucomannan                             3\n",
       "glycogen                                3\n",
       "alpha-glucan                            3\n",
       "Name: high_level_substr, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"high_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9963c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# top_k = 10\n",
    "K = 5\n",
    "known_unknown = False\n",
    "\n",
    "\n",
    "## Doc2Vec_DM model\n",
    "model_dm =  gensim.models.doc2vec.Doc2Vec.load(r\"Embedding_Models_10_12//doc2vec_dm\") \n",
    "model_dbow = gensim.models.doc2vec.Doc2Vec.load(r\"Embedding_Models_10_12//doc2vec_dbow\") \n",
    "model_cbow =gensim.models.word2vec.Word2Vec.load(r\"Embedding_Models_10_12//word2vec_cbow\") \n",
    "model_sg =gensim.models.word2vec.Word2Vec.load(r\"Embedding_Models_10_12//word2vec_sg\") \n",
    "model_fasttext_sg =gensim.models.word2vec.Word2Vec.load(r\"Embedding_Models_10_12//fasttext_sg\") \n",
    "model_fasttext_cbow =gensim.models.word2vec.Word2Vec.load(r\"Embedding_Models_10_12//fasttext_cbow\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adb0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overall_catch = []\n",
    "for top_k in tqdm(range(5,15)):\n",
    "    for featurizer in [\"countvectorizer\", \"doc2vec_dbow\", \"doc2vec_dm\", \"word2vec_cbow\", \"word2vec_sg\", \"fasttext_sg\", \"fasttext_cbow\"]:\n",
    "        print(\"Currently running for featurizer \"+ featurizer + \" with \" + str(top_k) + \" number of classes.\")\n",
    "        if featurizer == \"countvectorizer\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, None)\n",
    "        elif featurizer == \"doc2vec_dbow\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_dbow)\n",
    "        elif featurizer == \"doc2vec_dm\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_dm)\n",
    "        elif featurizer == \"word2vec_cbow\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_cbow)            \n",
    "        elif featurizer == \"word2vec_sg\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_sg)\n",
    "        elif featurizer == \"fasttext_sg\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_fasttext_sg)      \n",
    "        elif featurizer == \"fasttext_cbow\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_fasttext_cbow)   \n",
    "        \n",
    "        overall_catch.append([top_k, featurizer, avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, \n",
    "                             overall_report[\"precision\"], overall_report[\"recall\"], overall_report[\"f1-score\"]])\n",
    "        \n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ed398",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch = pd.DataFrame(overall_catch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch.columns = [\"num_substrates\", \"feature_method\", \"avg_accuracy\", \"avg_classwise_acc\",\n",
    "                         \"std_err_avg_acc\", \"std_err_avg_classwise_acc\", \"avg_precision\", \"avg_recall\", \"avg_f1_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7fc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch.to_csv(r\"Data\\Output\\Experiments\\results_by_k_shallow_learners_new_sup_new_unsup.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_the_best = overall_catch.loc[overall_catch.groupby('num_substrates')['avg_classwise_acc'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_the_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff86c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_best = keep_the_best.melt(id_vars=['num_substrates'], value_vars=['avg_accuracy', 'avg_classwise_acc', \"avg_precision\", \"avg_f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23403a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt_best = keep_the_best.melt(id_vars=['num_substrates'], value_vars=['avg_accuracy', 'avg_classwise_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5755bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_best.columns = ['num_substrates', 'metric_name', 'metric_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7230e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.lineplot(data=melt_best, x=\"num_substrates\", y=\"metric_value\", hue=\"metric_name\",  marker=\"o\")\n",
    "plt.title(\"Plot of classification metrics by number of substrates in the model\", fontsize = 20 ,weight = \"bold\")\n",
    "plt.xlabel(\"Number of Substrates\",  weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Metric Value\", weight = \"bold\", fontsize = 20)\n",
    "plt.xticks(range(5,15), weight = \"bold\", fontsize = 15)\n",
    "plt.yticks(weight = \"bold\", fontsize = 15, rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fec1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (20,10))\n",
    "# sns.lineplot(data=overall_catch, x=\"num_substrates\", y=\"avg_accuracy\", hue=\"feature_method\",  marker=\"o\")\n",
    "# plt.title(\"Plot of classification metrics by number of substrates in the model\", fontsize = 20 ,weight = \"bold\")\n",
    "# plt.xlabel(\"Number of Substrates\",  weight = \"bold\", fontsize = 20)\n",
    "# plt.ylabel(\"Metric Value\", weight = \"bold\", fontsize = 20)\n",
    "# plt.xticks(range(5,15), weight = \"bold\", fontsize = 15)\n",
    "# plt.yticks(weight = \"bold\", fontsize = 15, rotation = 0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f990ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "# filter_condn = [ \"countvectorizer\"]\n",
    "sns.lineplot(data=overall_catch,  x=\"num_substrates\", y=\"avg_accuracy\", hue=\"feature_method\",  marker=\"o\")\n",
    "plt.title(\"Plot of Average Accuracy by number of substrates for different feature extraction methods.\", fontsize = 20 ,weight = \"bold\")\n",
    "plt.xlabel(\"Number of Substrates\",  weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy Value\", weight = \"bold\", fontsize = 20)\n",
    "plt.xticks(range(5,15), weight = \"bold\", fontsize = 15)\n",
    "plt.yticks(weight = \"bold\", fontsize = 15, rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6632d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87aadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch_dl = []\n",
    "for top_k in tqdm(range(5,10)):\n",
    "# for top_k in tqdm(range(9,10)):    \n",
    "    for featurizer in [\"lstm_with_attention\", \"just_attention\", \"vanilla_lstm\"]:\n",
    "        print(\"Currently running for featurizer \"+ featurizer + \" with \" + str(top_k) + \" number of classes.\")\n",
    "        if featurizer == \"countvectorizer\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, None)\n",
    "        \n",
    "        elif featurizer == \"doc2vec_dbow\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_dbow)\n",
    "        \n",
    "        elif featurizer == \"doc2vec_dm\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_dm)\n",
    "        \n",
    "        elif featurizer == \"word2vec_cbow\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_cbow)            \n",
    "        \n",
    "        elif featurizer == \"word2vec_sg\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_sg)\n",
    "        \n",
    "        elif featurizer == \"fasttext_sg\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_fasttext_sg)      \n",
    "        \n",
    "        elif featurizer == \"fasttext_cbow\":\n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_fasttext_cbow)   \n",
    "        \n",
    "        elif featurizer == \"lstm_with_attention\": \n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_sg)\n",
    "        \n",
    "        elif featurizer == \"just_attention\": \n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_sg)        \n",
    "        \n",
    "        elif featurizer == \"vanilla_lstm\": \n",
    "            avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, overall_report,  model, params_best, fig, fig2, fig3 = run_end_to_end(top_k, data, featurizer, K, known_unknown, model_sg)        \n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        overall_catch_dl.append([top_k, featurizer, avg_acc, avg_class_acc, std_err_avg_acc, std_err_avg_classwise_acc, \n",
    "                             overall_report[\"precision\"], overall_report[\"recall\"], overall_report[\"f1-score\"]])\n",
    "        \n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69786634",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch_dl = pd.DataFrame(overall_catch_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e638667",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch_dl.columns = [\"num_substrates\", \"feature_method\", \"avg_accuracy\", \"avg_classwise_acc\",\n",
    "                         \"std_err_avg_acc\", \"std_err_avg_classwise_acc\", \"avg_precision\", \"avg_recall\", \"avg_f1_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67878750",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch_dl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch_dl.to_csv(r\"Data\\Output\\Experiments\\results_by_k_deep_learners_new_sup_new_unsup.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_the_best_dl = overall_catch_dl.loc[overall_catch_dl.groupby('num_substrates')['avg_classwise_acc'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f828879",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_the_best_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_best_dl = keep_the_best_dl.melt(id_vars=['num_substrates'], value_vars=['avg_accuracy', 'avg_classwise_acc', \"avg_precision\", \"avg_f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dade6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt_best = keep_the_best.melt(id_vars=['num_substrates'], value_vars=['avg_accuracy', 'avg_classwise_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d675be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_best_dl.columns = ['num_substrates', 'metric_name', 'metric_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.lineplot(data=melt_best_dl, x=\"num_substrates\", y=\"metric_value\", hue=\"metric_name\",  marker=\"o\")\n",
    "plt.title(\"Plot of classification metrics by number of substrates in the model\", fontsize = 20 ,weight = \"bold\")\n",
    "plt.xlabel(\"Number of Substrates\",  weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Metric Value\", weight = \"bold\", fontsize = 20)\n",
    "plt.xticks(range(5,15), weight = \"bold\", fontsize = 15)\n",
    "plt.yticks(weight = \"bold\", fontsize = 15, rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_catch_dl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c58f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (20,10))\n",
    "# sns.lineplot(data=overall_catch, x=\"num_substrates\", y=\"avg_accuracy\", hue=\"feature_method\",  marker=\"o\")\n",
    "# plt.title(\"Plot of classification metrics by number of substrates in the model\", fontsize = 20 ,weight = \"bold\")\n",
    "# plt.xlabel(\"Number of Substrates\",  weight = \"bold\", fontsize = 20)\n",
    "# plt.ylabel(\"Metric Value\", weight = \"bold\", fontsize = 20)\n",
    "# plt.xticks(range(5,15), weight = \"bold\", fontsize = 15)\n",
    "# plt.yticks(weight = \"bold\", fontsize = 15, rotation = 0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e15483",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "# filter_condn = [ \"countvectorizer\"]\n",
    "sns.lineplot(data=overall_catch_dl,  x=\"num_substrates\", y=\"avg_accuracy\", hue=\"feature_method\",  marker=\"o\")\n",
    "plt.title(\"Plot of Average Accuracy by number of substrates for different feature extraction methods.\", fontsize = 20 ,weight = \"bold\")\n",
    "plt.xlabel(\"Number of Substrates\",  weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy Value\", weight = \"bold\", fontsize = 20)\n",
    "plt.xticks(range(5,15), weight = \"bold\", fontsize = 15)\n",
    "plt.yticks(weight = \"bold\", fontsize = 15, rotation = 0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newone1",
   "language": "python",
   "name": "newone1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
